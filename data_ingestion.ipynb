{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6dcda2f-6fa9-45c1-995f-a48b103e806a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "from config import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Replace 'username/dataset-name' with the actual dataset path from Kaggle\n",
    "dataset_path = 'stealthtechnologies/employee-attrition-dataset'\n",
    "\n",
    "file_name = 'train.csv'  # Replace with the actual file name within the dataset\n",
    "\n",
    "Api_url = f'https://www.kaggle.com/api/v1/datasets/download/{dataset_path}'\n",
    "\n",
    "auth_key = '6d57bed32a8caffd1756380d5311811a'\n",
    "\n",
    "\n",
    "storage_path = \"C:\\\\Users\\\\acer\\\\100-days-of-machine-learning-main\\\\iDataMinds\\\\DE\\\\artifacts\"\n",
    "\n",
    "\n",
    "# Set up the Kaggle API URL for the dataset\n",
    "url = Api_url\n",
    "\n",
    "# Send request to Kaggle API\n",
    "headers = {'Authorization': auth_key} \n",
    "save_path = storage_path\n",
    "file_name = file_name\n",
    "\n",
    "\n",
    "def Data_ingestion(url, headers, save_path):\n",
    "    try:\n",
    "        response = requests.get(url,headers=headers, stream=True)\n",
    "        response.raise_for_status()\n",
    "    \n",
    "\n",
    "        # Extract and read the specific CSV file from the zip directly into a DataFrame\n",
    "        with ZipFile(BytesIO(response.content)) as z:\n",
    "            if file_name in z.namelist():\n",
    "                with z.open(file_name) as f:\n",
    "                    df = pd.read_csv(f)\n",
    "                    print(\"File loaded successfully\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"{file_name} not found in the downloaded zip file\")\n",
    "            \n",
    "\n",
    "        # Save the DataFrame to CSV\n",
    "\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(\"Data saved to 'train.csv' successfully!\")\n",
    "\n",
    "    # Handle specific errors\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err} [status code: {response.status_code if 'response' in locals() else 'unknown'}]\")\n",
    "    except FileNotFoundError as fnf_err:\n",
    "        print(f\"File error: {fnf_err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_ingestion",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
